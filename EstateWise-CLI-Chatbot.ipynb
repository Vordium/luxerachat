{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ufUz0Dwuc2v"
   },
   "source": [
    "# EstateWise Chapel Hill Real Estate Analysis & Gemini Chat CLI\n",
    "\n",
    "Welcome to the EstateWise Colab notebook, where we combine advanced data science techniques with Google’s Gemini API to explore and interact with Chapel Hill’s real estate market. Whether you’re digging into trends, clustering similar homes, or simply chatting with our AI concierge, this notebook has you covered.\n",
    "\n",
    "## This notebook covers\n",
    "\n",
    "1. **Install dependencies**\n",
    "2. **Mount Google Drive**\n",
    "3. **Load Properties Data**\n",
    "4. **Clean & wrangle data**\n",
    "5. **Exploratory Data Analysis (EDA)**\n",
    "6. **PCA / t-SNE + k-Means clustering**\n",
    "7. **Cluster summaries**\n",
    "8. **Interactive geospatial visualizations**\n",
    "   - **Price heatmap** (density weighted by listing price)\n",
    "   - **Living-area heatmap** (density weighted by square footage)\n",
    "   - **Price-per-square-foot heatmap** (gradient showing per-unit value)\n",
    "9. **Interactive Google Gemini CLI**\n",
    "   - Agentic AI decides when to fetch property data\n",
    "   - Five-expert ensemble with master-agent merge (MoE - Mixture of Experts Pipeline)\n",
    "   - Type your questions & get tailored Chapel Hill home recommendations in real time!\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://img.shields.io/badge/Python-3.11-blue?style=flat-square&logo=python&logoColor=white\" alt=\"Python\"/>\n",
    "  <img src=\"https://img.shields.io/badge/Jupyter-Notebook-orange?style=flat-square&logo=jupyter&logoColor=white\" alt=\"Jupyter Notebook\"/>\n",
    "  <img src=\"https://img.shields.io/badge/pandas-Data%20Wrangling-150458?style=flat-square&logo=pandas&logoColor=white\" alt=\"pandas\"/>\n",
    "  <img src=\"https://img.shields.io/badge/NumPy-Numerical%20Computing-013243?style=flat-square&logo=numpy&logoColor=white\" alt=\"NumPy\"/>\n",
    "  <img src=\"https://img.shields.io/badge/scikit--learn-ML-F7931E?style=flat-square&logo=scikitlearn&logoColor=white\" alt=\"scikit-learn\"/>\n",
    "  <img src=\"https://img.shields.io/badge/Matplotlib-Visualization-11557C?style=flat-square&logo=matplotlib&logoColor=white\" alt=\"Matplotlib\"/>\n",
    "  <img src=\"https://img.shields.io/badge/Seaborn-Statistical%20Viz-76B5C5?style=flat-square&logo=seaborn&logoColor=white\" alt=\"Seaborn\"/>\n",
    "  <img src=\"https://img.shields.io/badge/Folium-Mapping-00A5CF?style=flat-square&logo=mapbox&logoColor=white\" alt=\"Folium\"/>\n",
    "  <img src=\"https://img.shields.io/badge/Pinecone-Vector%20DB-663399?style=flat-square&logo=pinecone&logoColor=white\" alt=\"Pinecone\"/>\n",
    "  <img src=\"https://img.shields.io/badge/Google%20Gemini-AI-4285F4?style=flat-square&logo=google&logoColor=white\" alt=\"Google Gemini\"/>\n",
    "  <img src=\"https://img.shields.io/badge/python--dotenv-Configuration-3C873A?style=flat-square&logo=dotenv&logoColor=white\" alt=\"python-dotenv\"/>\n",
    "</p>\n",
    "\n",
    "> To run the code in this notebook, download the notebook and then upload it to [Google Colab](https://colab.research.google.com). Alternatively, go straight to [this Google Colab Notebook link](https://colab.research.google.com/drive/1-Z3h0LUHl0v-e0RaZgwruL8q180Uk4Z-?usp=sharing) to view & run it directly in Google Colab.\n",
    "\n",
    "> Before running the notebook's code, ensure that you have loaded the datasets to your Google Drive. If you prefer to not change any code, put your datasets (e.g. `Zillow-March2025-dataset_part0.json`, `Zillow-March2025-dataset_part1.json`, `Zillow-March2025-dataset_part2.json`, `Zillow-March2025-dataset_part3.json`) in the `COMP-488` folder in your Drive.\n",
    "\n",
    "> Note: If you plan to use all dataset files with this notebook (over 30,000 properties), make sure to select the v2-8 TPU runtime or higher. Otherwise, Colab may crash due to the large dataset size. This notebook has been successfully run on all files, handling more than 30,000 properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9n2WvnQ2svs3"
   },
   "source": [
    "# 1. Install Depenencies & Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQxCPdLOugsj",
    "outputId": "10581cf0-62ff-48c7-b20f-18c729d4248b"
   },
   "source": [
    "# 1. Install Dependencies\n",
    "!pip install --upgrade pandas numpy scikit-learn matplotlib seaborn google-generativeai python-dotenv"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7g9oIR4bsycA"
   },
   "source": [
    "# 2. Imports & Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EGvG_lwKvr1g",
    "outputId": "7358df1f-4ae8-48b3-c85b-e6aa3336f9d7"
   },
   "source": [
    "# 2. Imports & Mount Drive\n",
    "import os, glob, json, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Google Gemini client\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlG4SgzdxBbh"
   },
   "source": [
    "### 2.1 Configure Paths & API Key\n",
    "\n",
    "- Point `path488` to your Zillow JSON folder in Drive\n",
    "- Set `GOOGLE_API_KEY` in Colab’s environment (Settings → Secrets)\n",
    "- Set `PINECONE_API_KEY` in Colab’s environment (Settings → Secrets)\n",
    "- Set `PINECONE_ENVIRONMENT` in Colab’s environment (Settings → Secrets)\n",
    "- Set `PINECONE_INDEX` in Colab’s environment (Settings → Secrets)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CerHVXZTxC-K",
    "outputId": "6bba78b5-1829-4425-c0eb-f50fa7f2f2be"
   },
   "source": [
    "# Path to folder containing your Zillow JSONs\n",
    "path488 = '/content/drive/MyDrive/COMP-488/'\n",
    "zillowfiles = glob.glob(path488 + 'Zillow*.json')\n",
    "# Keep only 2025 files\n",
    "zillow25 = [f for f in zillowfiles if '2025' in f]\n",
    "print(\"Found 2025 JSON files:\", zillow25)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoBSp-xFxGS8"
   },
   "source": [
    "## 3. Load & Concatenate 2025 Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dvU8VxQxFQk",
    "outputId": "144ea1ca-9eb5-4005-c962-a296328e26a6"
   },
   "source": [
    "dfs = []\n",
    "for fp in zillow25:\n",
    "    with open(fp, 'r', encoding='utf8') as f:\n",
    "        arr = json.load(f)\n",
    "    dfs.append(pd.DataFrame(arr))\n",
    "df_raw = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"Raw 2025 records: {len(df_raw):,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJjNyRokxJDl"
   },
   "source": [
    "## 4. Data Cleaning & Wrangling\n",
    "\n",
    "- Keep only relevant fields\n",
    "- Apply safe parsing and drop invalid entries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZTIf4mfQxJv8"
   },
   "source": [
    "# 4.1 Helpers & field list\n",
    "def safe_str(val, fallback=\"Unknown\"):\n",
    "    return val.strip() if isinstance(val, str) and val.strip() else fallback\n",
    "\n",
    "def safe_num(val, fallback=0, mn=None, mx=None):\n",
    "    try:\n",
    "        n = float(val)\n",
    "    except:\n",
    "        return fallback\n",
    "    if mn is not None and n < mn:\n",
    "        return fallback\n",
    "    if mx is not None and n > mx:\n",
    "        return fallback\n",
    "    return n\n",
    "\n",
    "keep = [\n",
    "    \"zpid\",\"address\",\"city\",\"state\",\"bedrooms\",\"bathrooms\",\n",
    "    \"price\",\"yearBuilt\",\"livingArea\",\"latitude\",\"longitude\",\n",
    "    \"homeType\",\"listingDataSource\",\"description\"\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "sQkPcYw4xL8d",
    "outputId": "0754886e-0e39-4369-bb7b-25f5f9f40e8c"
   },
   "source": [
    "# 4.2 Clean records\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Helper functions\n",
    "def safe_num(val, default=0, min_val=None, max_val=None):\n",
    "    \"\"\"\n",
    "    Convert a value to float, applying bounds and default on failure or missing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isna(val):\n",
    "            return default\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # strip commas, whitespace\n",
    "        num = float(str(val).replace(\",\", \"\").strip())\n",
    "    except:\n",
    "        return default\n",
    "    if (min_val is not None and num < min_val) or (max_val is not None and num > max_val):\n",
    "        return default\n",
    "    return num\n",
    "\n",
    "def safe_int(val, default=0, min_val=None, max_val=None):\n",
    "    \"\"\"\n",
    "    Convert to int safely via safe_num, then cast.\n",
    "    \"\"\"\n",
    "    num = safe_num(val, default, min_val, max_val)\n",
    "    return int(round(num))\n",
    "\n",
    "def safe_float(val, default=0.0, min_val=None, max_val=None, step=0.5):\n",
    "    \"\"\"\n",
    "    Convert to float safely via safe_num, then round to nearest step (e.g. 0.5 for bathrooms).\n",
    "    \"\"\"\n",
    "    num = safe_num(val, default, min_val, max_val)\n",
    "    # round to nearest step\n",
    "    return round(num / step) * step\n",
    "\n",
    "def safe_str(val, default=\"Unknown\"):\n",
    "    \"\"\"\n",
    "    Ensure string, JSON-serialize dicts/lists, default if missing/empty.\n",
    "    \"\"\"\n",
    "    if val is None or (isinstance(val, float) and np.isnan(val)):\n",
    "        return default\n",
    "    if isinstance(val, (dict, list)):\n",
    "        try:\n",
    "            return json.dumps(val)\n",
    "        except:\n",
    "            return default\n",
    "    s = str(val).strip()\n",
    "    return s if s else default\n",
    "\n",
    "# 4.3 Clean records (improved)\n",
    "current_year = pd.Timestamp.now().year\n",
    "records = []\n",
    "\n",
    "for r in df_raw[keep].to_dict('records'):\n",
    "    # normalize address field if it's a JSON string\n",
    "    addr_field = r.get(\"address\")\n",
    "    if isinstance(addr_field, str):\n",
    "        try:\n",
    "            addr = json.loads(addr_field)\n",
    "        except:\n",
    "            addr = {}\n",
    "    else:\n",
    "        addr = addr_field or {}\n",
    "\n",
    "    # safe extraction\n",
    "    zpid = safe_int(r.get(\"zpid\"), default=0)\n",
    "    street = safe_str(addr.get(\"streetAddress\"), default=\"\")\n",
    "    city   = safe_str(addr.get(\"city\") or r.get(\"city\"), default=\"\")\n",
    "    state  = safe_str(addr.get(\"state\") or r.get(\"state\"), default=\"\")\n",
    "    zipcode= safe_str(addr.get(\"zipcode\"), default=\"\")\n",
    "\n",
    "    # skip if essential address components missing\n",
    "    if zpid == 0 or not street or not city or not state or not zipcode:\n",
    "        continue\n",
    "\n",
    "    # numeric fields\n",
    "    bedrooms  = safe_int(r.get(\"bedrooms\"), default=0, min_val=0, max_val=20)\n",
    "    bathrooms = safe_float(r.get(\"bathrooms\"), default=0.0, min_val=0, max_val=20, step=0.5)\n",
    "    price     = safe_num(r.get(\"price\"), default=0, min_val=10000, max_val=1e8)\n",
    "\n",
    "    # handle yearBuilt bounds\n",
    "    year_val = safe_int(r.get(\"yearBuilt\"), default=0)\n",
    "    if year_val < 1800 or year_val > current_year + 1:\n",
    "        yearBuilt = 0\n",
    "    else:\n",
    "        yearBuilt = year_val\n",
    "\n",
    "    livingArea = safe_num(r.get(\"livingArea\"), default=0, min_val=100, max_val=20000)\n",
    "\n",
    "    # geolocation\n",
    "    latitude  = safe_num(r.get(\"latitude\"), default=0.0, min_val=-90, max_val=90)\n",
    "    longitude = safe_num(r.get(\"longitude\"), default=0.0, min_val=-180, max_val=180)\n",
    "\n",
    "    # categorical/text fields\n",
    "    homeType           = safe_str(r.get(\"homeType\"))\n",
    "    listingDataSource  = safe_str(r.get(\"listingDataSource\"))\n",
    "    description        = safe_str(r.get(\"description\"), default=\"No description provided.\")\n",
    "\n",
    "    records.append({\n",
    "        \"zpid\": zpid,\n",
    "        \"street\": street,\n",
    "        \"city\": city,\n",
    "        \"state\": state,\n",
    "        \"zipcode\": zipcode,\n",
    "        \"bedrooms\": bedrooms,\n",
    "        \"bathrooms\": bathrooms,\n",
    "        \"price\": price,\n",
    "        \"yearBuilt\": yearBuilt,\n",
    "        \"livingArea\": livingArea,\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"homeType\": homeType,\n",
    "        \"listingDataSource\": listingDataSource,\n",
    "        \"description\": description,\n",
    "    })\n",
    "\n",
    "# create DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "print(f\"Cleaned records: {len(df):,}\")\n",
    "df.head()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpfJlSm8xNd7"
   },
   "source": [
    "## 5. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 925
    },
    "id": "ySxkCR0hxN6z",
    "outputId": "60b96715-945f-4aa5-d132-a31d5fe4ee0a"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# --- 5.1 Overview ---\n",
    "print(df.dtypes, \"\\n\")\n",
    "print(\"Missing values:\\n\", df.isna().sum(), \"\\n\")\n",
    "\n",
    "# --- 5.2 Summary stats ---\n",
    "display(df.describe().T)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zVlSRRx7xPsS",
    "outputId": "0db92d03-b5c7-459f-a070-560a58ee15a8"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "df_filtered = df[df[\"price\"].between(0, 20_000_000)]\n",
    "\n",
    "# --- 5.3 Price Distribution (Original) ---\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.histplot(df[\"price\"], bins=50, ax=ax)\n",
    "ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "ax.yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "ax.tick_params(axis='x', labelrotation=45)\n",
    "plt.setp(ax.get_xticklabels(), ha='right')\n",
    "\n",
    "ax.set_title(\"5.3 Price Distribution (All Prices)\")\n",
    "ax.set_xlabel(\"Price (USD)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- 5.3 Price Distribution (0–20 M USD) ---\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.histplot(df_filtered[\"price\"], bins=50, ax=ax)\n",
    "ax.set_xlim(0, 20_000_000)\n",
    "ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "ax.yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "ax.tick_params(axis='x', labelrotation=45)\n",
    "plt.setp(ax.get_xticklabels(), ha='right')\n",
    "\n",
    "ax.set_title(\"5.3 Price Distribution (0–20 M USD)\")\n",
    "ax.set_xlabel(\"Price (USD)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- 5.4 Price vs Living Area (Original) ---\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.scatterplot(x=\"livingArea\", y=\"price\", data=df, alpha=0.4, ax=ax)\n",
    "ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "ax.yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "ax.tick_params(axis='x', labelrotation=45)\n",
    "plt.setp(ax.get_xticklabels(), ha='right')\n",
    "\n",
    "ax.set_title(\"5.4 Price vs Living Area (All Prices)\")\n",
    "ax.set_xlabel(\"Living Area (sqft)\")\n",
    "ax.set_ylabel(\"Price (USD)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- 5.4 Price vs Living Area (0–20 M USD) ---\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.scatterplot(x=\"livingArea\", y=\"price\", data=df_filtered, alpha=0.4, ax=ax)\n",
    "ax.set_ylim(0, 20_000_000)\n",
    "ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "ax.yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "ax.tick_params(axis='x', labelrotation=45)\n",
    "plt.setp(ax.get_xticklabels(), ha='right')\n",
    "\n",
    "ax.set_title(\"5.4 Price vs Living Area (0–20 M USD)\")\n",
    "ax.set_xlabel(\"Living Area (sqft)\")\n",
    "ax.set_ylabel(\"Price (USD)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nwjP490FnTdq",
    "outputId": "dd3b5606-f097-4490-c0b9-b0677b13f4d0"
   },
   "source": [
    "if 'address' not in df.columns:\n",
    "    def make_address(row):\n",
    "        street = row.get('streetAddress', '') or ''\n",
    "        city   = row.get('city', '') or ''\n",
    "        state  = row.get('state', '') or ''\n",
    "        zipc   = row.get('zipcode', '') or ''\n",
    "        parts = [street, city, state, zipc]\n",
    "        return \", \".join([p for p in parts if p])\n",
    "    df['address'] = df.apply(make_address, axis=1)\n",
    "\n",
    "# 5.5 Bedrooms distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=\"bedrooms\", data=df)\n",
    "plt.title(\"Distribution of Number of Bedrooms\")\n",
    "plt.xlabel(\"Bedrooms\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.6 Bathrooms distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=\"bathrooms\", data=df)\n",
    "plt.title(\"Distribution of Number of Bathrooms\")\n",
    "plt.xlabel(\"Bathrooms\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.7 Year Built distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(df[\"yearBuilt\"].dropna(), bins=30)\n",
    "plt.title(\"Year Built Distribution\")\n",
    "plt.xlabel(\"Year Built\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.8 Correlation matrix heatmap\n",
    "corr = df[[\"price\", \"livingArea\", \"bedrooms\", \"bathrooms\", \"yearBuilt\"]].corr()\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.9 Boxplot of Price by Home Type\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x=\"homeType\", y=\"price\", data=df)\n",
    "plt.title(\"Price by Home Type\")\n",
    "plt.xlabel(\"Home Type\")\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.10 Top 10 most expensive properties\n",
    "top10 = df.nlargest(10, \"price\")[[\"address\", \"price\", \"bedrooms\", \"bathrooms\", \"livingArea\", \"yearBuilt\", \"homeType\"]]\n",
    "print(\"Top 10 Most Expensive Properties:\\n\", top10.to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWfUozqhxRS3"
   },
   "source": [
    "## 6. PCA, t-SNE & k‑Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GJMqgfaQxSQL",
    "outputId": "5079c70d-e6da-4d28-f054-ed9891c34644"
   },
   "source": [
    "# 6.1 Impute & Normalize features\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "features = [\"price\", \"bedrooms\", \"bathrooms\", \"livingArea\", \"yearBuilt\"]\n",
    "\n",
    "# 1) Impute missing values with column means\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_imputed = imputer.fit_transform(df[features])\n",
    "\n",
    "# 2) Scale to [0,1]\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# 6.2 PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "df[\"pca1\"], df[\"pca2\"] = pca.fit_transform(X).T\n",
    "\n",
    "# 6.3 t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=50)\n",
    "df[\"tsne1\"], df[\"tsne2\"] = tsne.fit_transform(X).T\n",
    "\n",
    "# 6.4 k-Means\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "df[\"cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "# Visualize clusters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.scatterplot(x=\"pca1\", y=\"pca2\", hue=\"cluster\", data=df, palette=\"tab10\", s=10)\n",
    "plt.title(\"PCA Projection by Cluster\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=\"tsne1\", y=\"tsne2\", hue=\"cluster\", data=df, palette=\"tab10\", s=10)\n",
    "plt.title(\"t-SNE Projection by Cluster\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2GOgKmuxWwC"
   },
   "source": [
    "## 7. Cluster Summaries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "oZFGZjJrxUw8",
    "outputId": "b6a17581-b93d-45c9-ee80-6efa2aa8a480"
   },
   "source": [
    "cluster_summary = df.groupby(\"cluster\").agg(\n",
    "    count=(\"zpid\",\"size\"),\n",
    "    avg_price=(\"price\",\"mean\"),\n",
    "    avg_sqft=(\"livingArea\",\"mean\"),\n",
    "    avg_year=(\"yearBuilt\",\"mean\")\n",
    ").round(2).reset_index()\n",
    "cluster_summary"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SC10B8aXqoOY"
   },
   "source": [
    "## 8. Interactive Geospatial Visualization of Listings\n",
    "\n",
    "In this section we’ll build three different interactive maps in Colab to explore our cleaned and clustered real estate listings:\n",
    "\n",
    "1. **Clustered Circle Markers with Layers**\n",
    "   - Centered on Chapel Hill, NC\n",
    "   - Fullscreen, measurement tool, and minimap controls\n",
    "   - One FeatureGroup per cluster (Cluster 0…Cluster 3), toggleable via the layer control\n",
    "   - Circle markers colored by cluster, with popups showing address, price, beds/baths, living area, year built\n",
    "\n",
    "2. **Home-Type Map with Search Bar**\n",
    "   - One FeatureGroup per `homeType` (e.g. Single Family, Condo)\n",
    "   - Search plugin to lookup any property by its full address\n",
    "   - Toggle layers for each home type via the layer control\n",
    "   - Popups and tooltips include type, price, and basic specs\n",
    "\n",
    "3. **Count-based MarkerCluster**\n",
    "   - MarkerCluster with custom div icons that display the number of listings in each cluster\n",
    "   - No heatmap—clusters simply show counts, and clicking expands individual markers with popups\n",
    "   - Layer control to toggle the count-cluster overlay\n",
    "\n",
    "Each map leverages **Folium** and supports intuitive pan/zoom, layer toggling, and rich popups/tooltips to help you visually explore spatial patterns in Chapel Hill real estate data. Simply run the corresponding code cells below to render each interactive map in your notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_dhGBYOk4_oX",
    "outputId": "474175bf-0805-40d6-bcf0-7d46abc34bb0"
   },
   "source": [
    "pip install folium"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cPlpqpkspNTP",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "outputId": "f292751f-9f99-4cab-fc5e-d5c80c8499d8"
   },
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster, HeatMap, MiniMap, Fullscreen, MeasureControl\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 8. Interactive Geospatial Visualization of Listings\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Define chunked‐loading options so markers are added in small, non-blocking batches\n",
    "cluster_opts = {\n",
    "    'chunkedLoading': True,\n",
    "    'chunkInterval': 100,   # ms of work per chunk\n",
    "    'chunkDelay': 5         # ms pause between chunks\n",
    "}\n",
    "\n",
    "# 8.1 Center map on Chapel Hill, NC\n",
    "chapel_hill_coords = [35.9132, -79.0558]\n",
    "m = folium.Map(\n",
    "    location=chapel_hill_coords,\n",
    "    zoom_start=13,\n",
    "    tiles='CartoDB positron',\n",
    "    control_scale=True\n",
    ")\n",
    "\n",
    "# 8.2 Add Fullscreen and Measure controls\n",
    "Fullscreen(position='topright').add_to(m)\n",
    "MeasureControl(position='topright', primary_length_unit='feet').add_to(m)\n",
    "\n",
    "# 8.3 Add a minimap inset\n",
    "MiniMap(toggle_display=True, position='bottomright').add_to(m)\n",
    "\n",
    "# 8.4 Prepare a color palette for clusters\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange', 'darkred', 'lightred', 'beige']\n",
    "cluster_colors = {c: colors[c % len(colors)] for c in sorted(df['cluster'].unique())}\n",
    "\n",
    "# 8.5 Create one hidden FeatureGroup + MarkerCluster for all properties\n",
    "cluster_fg = folium.FeatureGroup(name='Property Clusters', show=False)\n",
    "m.add_child(cluster_fg)\n",
    "marker_cluster = MarkerCluster(\n",
    "    name='Property Clusters',\n",
    "    options={\n",
    "        **cluster_opts,\n",
    "        'spiderfyOnMaxZoom': False,\n",
    "        'disableClusteringAtZoom': 17,\n",
    "        'maxClusterRadius': 35\n",
    "    }\n",
    ").add_to(cluster_fg)\n",
    "\n",
    "# 8.6 Add all listings into the single MarkerCluster\n",
    "for _, row in df.iterrows():\n",
    "    lat, lon = row['latitude'], row['longitude']\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        continue\n",
    "\n",
    "    c = row['cluster']\n",
    "    color = cluster_colors[c]\n",
    "\n",
    "    popup_html = (\n",
    "        f\"<strong>{row['street']}, {row['city']}</strong><br>\"\n",
    "        f\"Price: ${row['price']:,}<br>\"\n",
    "        f\"Beds: {row['bedrooms']}, Baths: {row['bathrooms']}<br>\"\n",
    "        f\"Area: {row['livingArea']} sqft, Year: {row['yearBuilt']}<br>\"\n",
    "        f\"Cluster: {c}\"\n",
    "    )\n",
    "    tooltip = f\"${row['price']:,} — {row['bedrooms']}bd/{row['bathrooms']}ba\"\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=(lat, lon),\n",
    "        radius=4,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=color,\n",
    "        fill_opacity=0.5,\n",
    "        popup=folium.Popup(popup_html, max_width=250),\n",
    "        tooltip=tooltip\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# 8.7 Price Heatmap layer (visible by default)\n",
    "heat_fg = folium.FeatureGroup(name='Price Heatmap', show=True)\n",
    "m.add_child(heat_fg)\n",
    "heat_data = df[['latitude', 'longitude', 'price']].dropna().values.tolist()\n",
    "HeatMap(\n",
    "    data=heat_data,\n",
    "    name='Price Heatmap',\n",
    "    min_opacity=0.3,\n",
    "    radius=8,\n",
    "    blur=5,\n",
    "    max_zoom=1\n",
    ").add_to(heat_fg)\n",
    "\n",
    "# 8.8 Layer control (clusters unchecked, heatmap checked)\n",
    "folium.LayerControl(collapsed=False, position='topright').add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.9 Price Heatmap Guide & Interpretation\n",
    "\n",
    "#### 8.9.1. Guide\n",
    "\n",
    "The heatmap layer overlays a semi‐transparent “intensity” map on top of the base map. It encodes **both spatial density** and **price weight** of the listings:\n",
    "\n",
    "- **Color gradient**\n",
    "  - **Cool colors (blue)** represent areas with relatively **few** or **lower‐priced** listings.\n",
    "  - **Warm colors (yellow → red)** indicate areas with **many** and/or **higher‐priced** listings.\n",
    "\n",
    "- **Intensity / Opacity**\n",
    "  - Brighter, more opaque spots show where high‐price listings cluster closely together.\n",
    "  - Fainter, more transparent spots show sparser or lower‐price concentrations.\n",
    "\n",
    "- **Radius & Blur settings**\n",
    "  - Each listing contributes to a circular “footprint” (radius = 8 px) that is blurred (blur = 5 px) to create a smooth gradient.\n",
    "  - A larger radius or blur makes hot spots spread out, while smaller values concentrate them tightly around each point.\n",
    "\n",
    "- **Weighting by Price**\n",
    "  - Because we passed `[lat, lon, price]` as each data point, pricier listings contribute more to the heatmap intensity than cheaper ones.\n",
    "  - Areas with both high listing counts *and* high prices will therefore appear hottest (deep red).\n",
    "\n",
    "Use this layer to quickly identify neighborhoods where expensive homes are concentrated versus those dominated by lower‐priced or fewer listings. You can also toggle the clusters on/off in the layer control at the top right.\n",
    "\n",
    "### 8.9.2 Interpretation\n",
    "\n",
    "This layer shows relative listing‐price density across Chapel Hill, using a blue→green→red gradient (blue = low, green = mid, red = high).\n",
    "\n",
    "- **Greenish areas near UNC (e.g. E Franklin St.)**\n",
    "  These are mid-to-high price pockets—reflecting student rentals, townhomes and smaller single-family homes that command steady demand but aren’t the priciest in town.\n",
    "\n",
    "- **Localized red hotspots within those green zones**\n",
    "  Indicate clusters of premium listings (large homes or newly built properties) fetching the highest prices per square foot, even among an already expensive corridor.\n",
    "\n",
    "- **Wider green bands in central Chapel Hill**\n",
    "  Show established residential neighborhoods with moderate price levels—balanced value between proximity to amenities and home size.\n",
    "\n",
    "- **Blue-ish outskirts**\n",
    "  Reveal more affordable sectors—older subdivisions or edge-of-town areas where average listing prices drop off, offering entry-level options further from the center."
   ],
   "metadata": {
    "id": "0beQbNmY9_61"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "id": "8lPtxeF9qBRq",
    "outputId": "1161b2ad-2cb9-45d5-9989-832ba262d013"
   },
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap, MiniMap, Fullscreen, MeasureControl\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 8.10 Interactive Geospatial Visualization of Living Area\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# 8.10 Center map on Chapel Hill, NC\n",
    "living_area_map = folium.Map(\n",
    "    location=chapel_hill_coords,     # reuse coords from previous map\n",
    "    zoom_start=13,\n",
    "    tiles='CartoDB positron',\n",
    "    control_scale=True\n",
    ")\n",
    "\n",
    "# 8.11 Add Fullscreen and Measure controls\n",
    "Fullscreen(position='topright').add_to(living_area_map)\n",
    "MeasureControl(position='topright', primary_length_unit='feet').add_to(living_area_map)\n",
    "\n",
    "# 8.12 Add a minimap inset\n",
    "MiniMap(toggle_display=True, position='bottomright').add_to(living_area_map)\n",
    "\n",
    "# 8.13 Living Area Heatmap layer (density weighted by livingArea)\n",
    "living_area_data = df[['latitude', 'longitude', 'livingArea']].dropna().values.tolist()\n",
    "HeatMap(\n",
    "    data=living_area_data,\n",
    "    name='Living Area Heatmap',\n",
    "    min_opacity=0.3,\n",
    "    radius=8,\n",
    "    blur=5,\n",
    "    max_zoom=1\n",
    ").add_to(living_area_map)\n",
    "\n",
    "# 8.14 Layer control (heatmap visible by default)\n",
    "folium.LayerControl(collapsed=False, position='topright').add_to(living_area_map)\n",
    "\n",
    "# Display the map\n",
    "living_area_map\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.15 Living‐Area Heatmap Guide & Interpretation\n",
    "\n",
    "#### 8.15.1 Guide\n",
    "\n",
    "The living‐area heatmap overlays a semi-transparent “intensity” layer on the base map, encoding both **spatial density** and **square-footage weight** of each listing:\n",
    "\n",
    "- **Color gradient**\n",
    "  - **Cool colors (blue)** represent areas with relatively **few** or **smaller-sized** listings.\n",
    "  - **Warm colors (yellow → red)** indicate areas with **many** and/or **larger** homes.\n",
    "\n",
    "- **Intensity / Opacity**\n",
    "  - Brighter, more opaque spots show where large-square-foot listings cluster tightly.\n",
    "  - Fainter, more transparent areas indicate sparser or smaller-sized concentrations.\n",
    "\n",
    "- **Radius & Blur settings**\n",
    "  - Each listing contributes a circular footprint (radius = 8 px) that’s blurred (blur = 5 px) for smooth transitions.\n",
    "  - Smaller radii concentrate heat around individual points; larger radii spread it out.\n",
    "\n",
    "- **Weighting by Living Area**\n",
    "  - Because we passed `[lat, lon, livingArea]` into the heatmap, listings with more square footage contribute more to the intensity than compact ones.\n",
    "  - Neighborhoods featuring both high listing counts **and** large homes will therefore appear hottest (deep red).\n",
    "\n",
    "Use this layer to spot where the biggest homes are clustered versus areas dominated by smaller dwellings. You can toggle other layers (cluster markers, price heatmap, etc.) on and off via the layer control.\n",
    "\n",
    "#### 8.15.2 Interpretation\n",
    "\n",
    "- **Widespread green around UNC and central Chapel Hill**\n",
    "  Indicates a high density of mid-sized homes—common student rentals, townhouses, and modest single-family houses close to campus.\n",
    "\n",
    "- **Red-tinged “dots” within those green zones**\n",
    "  Mark pockets of very large homes or new luxury developments that exceed the surrounding average square footage.\n",
    "\n",
    "- **Shrinking green clusters with distance**\n",
    "  Shows that as you move farther from the center, fewer large-footprint homes are listed, and overall home sizes trend smaller.\n",
    "\n",
    "By comparing this living‐area layer with the price or price-per-sqft maps, you can decide whether larger homes command proportional prices or represent undervalued opportunities in certain neighborhoods.\n"
   ],
   "metadata": {
    "id": "jZIOca1pFp5c"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "id": "kDgaxzYVqZ7H",
    "outputId": "95f6566c-1704-4082-fa25-bc3a3c7a97b0"
   },
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap, MiniMap, Fullscreen, MeasureControl\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 8.16 Interactive Geospatial Visualization of Price per Square Foot\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# 8.16 Center map on Chapel Hill, NC\n",
    "price_psf_map = folium.Map(\n",
    "    location=chapel_hill_coords,     # reuse coords from previous maps\n",
    "    zoom_start=13,\n",
    "    tiles='CartoDB positron',\n",
    "    control_scale=True\n",
    ")\n",
    "\n",
    "# 8.17 Add Fullscreen and Measure controls\n",
    "Fullscreen(position='topright').add_to(price_psf_map)\n",
    "MeasureControl(position='topright', primary_length_unit='feet').add_to(price_psf_map)\n",
    "\n",
    "# 8.18 Add a minimap inset\n",
    "MiniMap(toggle_display=True, position='bottomright').add_to(price_psf_map)\n",
    "\n",
    "# 8.19 Compute price per square foot and prepare heatmap data\n",
    "df['price_per_sqft'] = df['price'] / df['livingArea']\n",
    "price_psf_data = df[['latitude', 'longitude', 'price_per_sqft']].dropna().values.tolist()\n",
    "\n",
    "# 8.20 Price-per-sqft Heatmap layer (visible by default)\n",
    "# Note: gradient keys must be strings so folium doesn’t try to camelCase them\n",
    "HeatMap(\n",
    "    data=price_psf_data,\n",
    "    name='Price per Sqft Heatmap',\n",
    "    min_opacity=0.3,\n",
    "    radius=8,\n",
    "    blur=5,\n",
    "    max_zoom=1,\n",
    "    gradient={\n",
    "        '0.2': 'blue',\n",
    "        '0.4': 'lime',\n",
    "        '0.6': 'yellow',\n",
    "        '0.8': 'orange',\n",
    "        '1.0': 'red'\n",
    "    }\n",
    ").add_to(price_psf_map)\n",
    "\n",
    "# 8.21 Layer control (heatmap visible by default)\n",
    "folium.LayerControl(collapsed=False, position='topright').add_to(price_psf_map)\n",
    "\n",
    "# Display the map\n",
    "price_psf_map\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.22 Interpretation of Price per Square Foot Heatmap\n",
    "\n",
    "This heatmap highlights the spatial variation in value — how much each square foot of living space costs across Chapel Hill.\n",
    "\n",
    "- **Red “hot spots”** show neighborhoods where you pay a premium per square foot, often corresponding to historically desirable areas close to downtown or the UNC campus.\n",
    "- **Blue “cooler zones”** indicate more affordable pockets where larger homes may be available at lower per-square-foot rates, such as newer subdivisions on the outskirts.\n",
    "- **Transitional corridors** (green-to-yellow bands) along major roads suggest mixed price points—areas where mid-range properties and townhomes create a broader spread of values.\n",
    "- **Comparison with raw price map**: A neighborhood might have high overall prices but only moderate price-per-sqft (large lot sizes), or vice versa (smaller homes driving up per-sqft cost), helping you discern true value versus absolute price.\n",
    "- **Investment insight**: Cooler areas with rising price-per-sqft trends may signal emerging markets, while established hotspots warrant premium budgets.\n"
   ],
   "metadata": {
    "id": "_mQi8PLJHMwv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "import numpy as np\n",
    "from branca.colormap import StepColormap\n",
    "from folium.plugins import MiniMap, Fullscreen, MeasureControl\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 8.33 Interactive Geospatial Visualization of Grid-Based Composite Score\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# 8.33 Center map on Chapel Hill, NC\n",
    "grid_score_map = folium.Map(\n",
    "    location=chapel_hill_coords,  # reuse coords\n",
    "    zoom_start=13,\n",
    "    tiles='CartoDB positron',\n",
    "    control_scale=True\n",
    ")\n",
    "\n",
    "# 8.34 Add Fullscreen and Measure controls\n",
    "Fullscreen(position='topright').add_to(grid_score_map)\n",
    "MeasureControl(position='topright', primary_length_unit='feet').add_to(grid_score_map)\n",
    "\n",
    "# 8.35 Add a minimap inset\n",
    "MiniMap(toggle_display=True, position='bottomright').add_to(grid_score_map)\n",
    "\n",
    "# 8.36 Compute price_per_sqft if not already present\n",
    "if 'price_per_sqft' not in df:\n",
    "    df['price_per_sqft'] = df['price'] / df['livingArea']\n",
    "\n",
    "# 8.37 Define a regular lat/lon grid (~0.005° ≈ 500 m cells)\n",
    "lat_min, lat_max = df['latitude'].min(), df['latitude'].max()\n",
    "lon_min, lon_max = df['longitude'].min(), df['longitude'].max()\n",
    "grid_size = 0.005\n",
    "lat_bins = np.arange(lat_min, lat_max + grid_size, grid_size)\n",
    "lon_bins = np.arange(lon_min, lon_max + grid_size, grid_size)\n",
    "\n",
    "df['lat_bin'] = pd.cut(\n",
    "    df['latitude'],\n",
    "    bins=lat_bins,\n",
    "    include_lowest=True,\n",
    "    labels=lat_bins[:-1]\n",
    ")\n",
    "df['lon_bin'] = pd.cut(\n",
    "    df['longitude'],\n",
    "    bins=lon_bins,\n",
    "    include_lowest=True,\n",
    "    labels=lon_bins[:-1]\n",
    ")\n",
    "\n",
    "# 8.38 Aggregate metrics per grid cell\n",
    "grid = (\n",
    "    df\n",
    "    .dropna(subset=['lat_bin', 'lon_bin'])\n",
    "    .groupby(['lat_bin', 'lon_bin'], observed=False)\n",
    "    .agg(\n",
    "        count=('price', 'count'),\n",
    "        avg_psf=('price_per_sqft', 'mean'),\n",
    "        avg_area=('livingArea', 'mean'),\n",
    "        avg_beds=('bedrooms', 'mean')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "grid = grid[grid['count'] >= 3]\n",
    "\n",
    "# 8.39 Compute percentile ranks (0–1) for each metric\n",
    "for col in ['avg_psf', 'avg_area', 'avg_beds']:\n",
    "    grid[col + '_pct'] = grid[col].rank(pct=True, method='average')\n",
    "\n",
    "# 8.40 Compute composite score (mean percentile × 100)\n",
    "grid['score'] = grid[['avg_psf_pct', 'avg_area_pct', 'avg_beds_pct']].mean(axis=1) * 100\n",
    "\n",
    "# 8.41 Drop NaN scores\n",
    "grid = grid.dropna(subset=['score'])\n",
    "\n",
    "# 8.42 Prepare a stepped colormap\n",
    "colormap = StepColormap(\n",
    "    colors=['green', 'yellow', 'orange', 'red'],\n",
    "    index=[0, 25, 50, 75, 100],\n",
    "    vmin=0, vmax=100,\n",
    "    caption='Grid Composite Score (Percentile-Based)'\n",
    ")\n",
    "colormap.add_to(grid_score_map)\n",
    "\n",
    "# 8.43 Plot a label at each cell’s centroid showing its score\n",
    "for _, row in grid.iterrows():\n",
    "    lat_ctr = float(row['lat_bin']) + grid_size / 2\n",
    "    lon_ctr = float(row['lon_bin']) + grid_size / 2\n",
    "    sc = row['score']\n",
    "    color = colormap(sc)\n",
    "    folium.map.Marker(\n",
    "        location=(lat_ctr, lon_ctr),\n",
    "        icon=folium.DivIcon(\n",
    "            html=(\n",
    "                f'<div style=\"background:{color}; '\n",
    "                'border-radius:50%; width:24px; height:24px; '\n",
    "                'line-height:24px; text-align:center; '\n",
    "                'font-size:10px; color:white; font-weight:bold;\">'\n",
    "                f'{int(round(sc))}</div>'\n",
    "            )\n",
    "        )\n",
    "    ).add_to(grid_score_map)\n",
    "\n",
    "# 8.44 Layer control\n",
    "folium.LayerControl(collapsed=False, position='topright').add_to(grid_score_map)\n",
    "\n",
    "# Display the map\n",
    "grid_score_map\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "u6GjVVOcHhvm",
    "outputId": "91412970-f9de-4fb6-fd7f-bf0a32813d80"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.45 Interpretation of Percentile-Based Composite Score Map\n",
    "\n",
    "This grid-based map uses percentile ranking to show how each ~500 m cell stacks up relative to all others on a combined index of average price / sq ft, living area, and bedroom count. Scores run from 0 (lowest overall) to 100 (highest overall).\n",
    "\n",
    "- **Red cells (scores ≥ 75)**\n",
    "  These are the top-quartile areas in Chapel Hill, where homes tend to command the highest per-square-foot rates, offer larger living spaces, and include more bedrooms compared to most other cells. They typically correspond to established, high-demand neighborhoods close to UNC and downtown.\n",
    "\n",
    "- **Orange-to-yellow cells (scores 25 – 74)**\n",
    "  Occupying the middle two quartiles, these zones feature moderate combinations of value, size, and bedroom count. You’ll find mixed-price developments, suburban corridors, and transitional neighborhoods here—areas with solid amenities but fewer premium attributes.\n",
    "\n",
    "- **Green cells (scores < 25)**\n",
    "  Represent the bottom-quartile cells, where either smaller homes, lower price / sq ft, or fewer bedrooms dominate. These are often more affordable pockets, older subdivisions, or outlying sectors of Chapel Hill.\n",
    "\n",
    "- **Percentile-based scaling** allows you to see not just absolute metrics but relative performance—ideal for quickly spotting outlier grids (both premium enclaves and value opportunities) without being skewed by extreme outliers in price or size.\n",
    "\n",
    "### 8.46 Explanation of Composite Score Factors & Calculation\n",
    "\n",
    "The composite score for each ~500 m grid cell is built from three equally‐weighted property metrics:\n",
    "\n",
    "1. **Average Price per Square Foot (`avg_psf`)**\n",
    "   - Captures how much you pay for living space in that cell.\n",
    "2. **Average Living Area (`avg_area`)**\n",
    "   - Reflects the typical home size (in square feet) within the cell.\n",
    "3. **Average Bedroom Count (`avg_beds`)**\n",
    "   - Measures how many bedrooms the average listing offers.\n",
    "\n",
    "**Calculation steps**\n",
    "1. **Compute cell averages**\n",
    "   - For each occupied grid cell, take the mean of `price / livingArea`, `livingArea`, and `bedrooms`.\n",
    "2. **Convert to percentiles**\n",
    "   - Rank each cell’s value for a metric against all cells (percentile from 0 to 1).\n",
    "   - This ensures that, for example, a cell in the 90th percentile on `avg_psf` is more expensive than 90% of all cells.\n",
    "3. **Average percentiles**\n",
    "   - Take the mean of the three percentile values: `(psf_pct + area_pct + beds_pct) / 3.`\n",
    "4. **Scale to 0–100**\n",
    "   - Multiply the mean percentile by 100 to produce a human-readable score.\n",
    "   - A cell with a score of 80 means it ranks in the top 20% overall across the three factors; a score of 20 means it’s in the bottom 20%.\n",
    "\n",
    "By using percentile ranks rather than raw values, the composite score balances differences in scale (e.g., dollars vs. square feet) and prevents any single metric with extreme outliers from dominating the index.\n"
   ],
   "metadata": {
    "id": "Z24KsMkrKq4d"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaayaptWxbXU"
   },
   "source": [
    "## 9. Interactive Google Gemini CLI\n",
    "\n",
    "This notebook cell lets you chat **directly** with Google Gemini from Colab—no additional backend required. You’ll tap into our real estate–focused assistant and Pinecone property index right from your notebook.\n",
    "\n",
    "**Before you run this cell:**\n",
    "- Go to **Colab → Secrets & variables → Notebook secrets** and add:\n",
    "  - `GOOGLE_API_KEY` = your Google AI API key\n",
    "  - `PINECONE_API_KEY` = your Pinecone API key\n",
    "  - `PINECONE_ENVIRONMENT` = your Pinecone environment (e.g. `us-west1-gcp`)\n",
    "  - `PINECONE_INDEX` = the name of your Pinecone index (e.g. `estatewise-index`)\n",
    "- Make sure you click **Save** so that `userdata.get()` can retrieve them at runtime.\n",
    "\n",
    "**How it works:**\n",
    "1. **Load credentials** from your Colab secrets.\n",
    "2. **Initialize** the Gemini client and Pinecone index.\n",
    "3. **Agentic decision**: the assistant will decide if it needs to fetch property embeddings & metadata or just use conversation context.\n",
    "4. **Expert ensemble**: five specialized “agents” (Data Analyst, Lifestyle Concierge, Financial Advisor, Neighborhood Expert, Cluster Analyst) each produce their view in parallel.\n",
    "5. A **Master Agent** synthesizes all expert opinions into one cohesive, concise recommendation—always providing at least one property suggestion.\n",
    "6. **CLI loop**: type your queries at the prompt, get back rich property recommendations, and type `exit` or `quit` to end the session.\n",
    "\n",
    "_For a full web-app experience with polished UI and persistence, check out our deployed version at_\n",
    "https://estatewise.vercel.app/\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rim-YZncVdg1",
    "outputId": "cf1577a8-f296-4656-9651-9eb4bf4385e6"
   },
   "source": [
    "pip install pinecone google-genai python-dotenv"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-knFj08PxcAr",
    "outputId": "84935776-22d8-4274-a7a4-800a97238292"
   },
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import concurrent.futures\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from pinecone import Pinecone\n",
    "from google.colab import userdata\n",
    "\n",
    "# 1) Load API keys from Colab secrets\n",
    "load_dotenv()\n",
    "api_key = userdata.get('GOOGLE_API_KEY')\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"Set GOOGLE_API_KEY in Colab secrets\")\n",
    "pinecone_api_key = userdata.get('PINECONE_API_KEY')\n",
    "pinecone_env     = userdata.get('PINECONE_ENVIRONMENT')\n",
    "pinecone_index   = userdata.get('PINECONE_INDEX')\n",
    "if not (pinecone_api_key and pinecone_env and pinecone_index):\n",
    "    raise RuntimeError(\"Set PINECONE_API_KEY, PINECONE_ENVIRONMENT, and PINECONE_INDEX in Colab secrets\")\n",
    "\n",
    "# 2) Initialize clients\n",
    "client = genai.Client(api_key=api_key)\n",
    "pc = Pinecone(api_key=pinecone_api_key, environment=pinecone_env)\n",
    "index = pc.Index(pinecone_index)\n",
    "\n",
    "# 3) Pinecone helpers\n",
    "def sanitize_metadata(md: dict) -> dict:\n",
    "    out = {}\n",
    "    for k, v in (md or {}).items():\n",
    "        if isinstance(v, (str, int, float, bool)):\n",
    "            out[k] = v\n",
    "        elif isinstance(v, list):\n",
    "            out[k] = \", \".join(v) if all(isinstance(x, str) for x in v) else json.dumps(v)\n",
    "        elif isinstance(v, dict):\n",
    "            out[k] = json.dumps(v)\n",
    "        else:\n",
    "            out[k] = str(v)\n",
    "    return out\n",
    "\n",
    "def query_properties(query: str, top_k: int = 30):\n",
    "    emb = client.embeddings.create(model=\"models/text-embedding-004\", content=query)\n",
    "    vec = emb.data[0].embedding\n",
    "    resp = index.query(vector=vec, top_k=top_k, include_metadata=True)\n",
    "    matches = getattr(resp, \"matches\", resp.get(\"matches\", []))\n",
    "    return [\n",
    "        {\n",
    "            \"id\": getattr(m, \"id\", m.get(\"id\")),\n",
    "            \"score\": getattr(m, \"score\", m.get(\"score\", 0.0)),\n",
    "            \"metadata\": sanitize_metadata(getattr(m, \"metadata\", m.get(\"metadata\", {})))\n",
    "        }\n",
    "        for m in matches\n",
    "    ]\n",
    "\n",
    "def query_properties_as_string(query: str, top_k: int = 30) -> str:\n",
    "    props = query_properties(query, top_k)\n",
    "    if not props:\n",
    "        return \"No matching properties found.\"\n",
    "    out = \"Matching Properties:\\n\\n\"\n",
    "    for r in props:\n",
    "        m = r[\"metadata\"]\n",
    "        addr = {}\n",
    "        if \"address\" in m:\n",
    "            try: addr = json.loads(m[\"address\"])\n",
    "            except: addr = {}\n",
    "        street = addr.get(\"streetAddress\", \"Unknown\")\n",
    "        city   = addr.get(\"city\", \"Unknown\")\n",
    "        state  = addr.get(\"state\", \"Unknown\")\n",
    "        zipc   = addr.get(\"zipcode\", \"\")\n",
    "        price  = f\"${m['price']}\" if m.get(\"price\") else \"N/A\"\n",
    "        beds   = m.get(\"bedrooms\", \"N/A\")\n",
    "        baths  = m.get(\"bathrooms\", \"N/A\")\n",
    "        area   = f\"{m['livingArea']} sqft\" if m.get(\"livingArea\") else \"N/A\"\n",
    "        year   = m.get(\"yearBuilt\", \"N/A\")\n",
    "        htype  = m.get(\"homeType\", \"N/A\")\n",
    "        desc   = m.get(\"description\", \"No description\")\n",
    "        zpid   = str(m.get(\"zpid\", \"\"))\n",
    "        link   = f\"https://www.zillow.com/homedetails/{zpid}_zpid/\" if zpid else \"N/A\"\n",
    "        out += (\n",
    "            f\"Property at {street}, {city}, {state} {zipc}\\n\"\n",
    "            f\"  - Price: {price}\\n\"\n",
    "            f\"  - Beds: {beds}, Baths: {baths}\\n\"\n",
    "            f\"  - Living Area: {area}\\n\"\n",
    "            f\"  - Year Built: {year}\\n\"\n",
    "            f\"  - Type: {htype}\\n\"\n",
    "            f\"  - Description: {desc}\\n\"\n",
    "            f\"  - More details: {link}\\n\\n\"\n",
    "        )\n",
    "    return out\n",
    "\n",
    "# 4) K-Means clustering\n",
    "def kmeans(data: list[list[float]], k: int, max_iter: int = 20) -> list[int]:\n",
    "    if not data or k <= 0:\n",
    "        return []\n",
    "    n, dims = len(data), len(data[0])\n",
    "    centroids = [row.copy() for row in data[:min(k, n)]]\n",
    "    while len(centroids) < k:\n",
    "        centroids.append(data[-1].copy())\n",
    "    assign = [0] * n\n",
    "    for _ in range(max_iter):\n",
    "        moved = False\n",
    "        for i, pt in enumerate(data):\n",
    "            dists = [sum((pt[d] - c[d])**2 for d in range(dims)) for c in centroids]\n",
    "            c = dists.index(min(dists))\n",
    "            if assign[i] != c:\n",
    "                assign[i] = c\n",
    "                moved = True\n",
    "        if not moved:\n",
    "            break\n",
    "        sums = [[0]*dims for _ in range(k)]\n",
    "        counts = [0]*k\n",
    "        for i, pt in enumerate(data):\n",
    "            c = assign[i]\n",
    "            counts[c] += 1\n",
    "            for d in range(dims):\n",
    "                sums[c][d] += pt[d]\n",
    "        for c in range(k):\n",
    "            if counts[c]:\n",
    "                centroids[c] = [sums[c][d]/counts[c] for d in range(dims)]\n",
    "    return assign\n",
    "\n",
    "# 5) Chat function with agentic decision\n",
    "CLUSTER_COUNT = 4\n",
    "MAX_HISTORY = 20\n",
    "\n",
    "def chat_with_estatewise(history: list[str], message: str, user_context: str = \"\", expert_weights: dict[str,float] = None):\n",
    "    expert_weights = expert_weights or {}\n",
    "    start = time.time()\n",
    "    low = message.strip().lower()\n",
    "\n",
    "    # 5.0) Greeting / thanks shortcuts\n",
    "    if low in (\"hi\", \"hello\", \"hey\"):\n",
    "        return \"Hello! How can I assist you today?\", {}\n",
    "    if low in (\"thanks\", \"thank you\"):\n",
    "        return \"You're welcome! Let me know if you need anything else.\", {}\n",
    "\n",
    "    # trim history\n",
    "    hist = history[-MAX_HISTORY*2:]\n",
    "    hist_str = \"\\n\".join(f\"User: {m}\" if i%2==0 else f\"Assistant: {m}\"\n",
    "                         for i, m in enumerate(hist))\n",
    "\n",
    "    # 5.1) Agentic decision: should we fetch property data?\n",
    "    decision_prompt = (\n",
    "        \"You are EstateWise Assistant. First decide whether you need to fetch property data to answer the user. \"\n",
    "        \"If the message is small talk (greetings, thanks) or does not ask about properties, answer 'No'. \"\n",
    "        \"Otherwise answer 'Yes'.\\n\\n\"\n",
    "        f\"User message:\\n\\\"{message}\\\"\\n\\n\"\n",
    "        \"Respond with exactly 'Yes' or 'No'.\"\n",
    "    )\n",
    "    decision = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=decision_prompt\n",
    "    ).text.strip().lower()\n",
    "    should_fetch = decision.startswith(\"yes\")\n",
    "\n",
    "    # 5.2) Fetch & cluster if needed\n",
    "    combined = \"\"\n",
    "    if should_fetch:\n",
    "        try:\n",
    "            prop_text = query_properties_as_string(message)\n",
    "            raw = query_properties(message)\n",
    "        except:\n",
    "            prop_text, raw = \"\", []\n",
    "        if raw:\n",
    "            vecs = []\n",
    "            for r in raw:\n",
    "                m = r[\"metadata\"]\n",
    "                def to_num(x):\n",
    "                    s = re.sub(r\"[^0-9.\\-]\", \"\", str(x) or \"0\")\n",
    "                    return float(s) if s else 0.0\n",
    "                vecs.append([\n",
    "                    to_num(m.get(\"price\")), to_num(m.get(\"bedrooms\")),\n",
    "                    to_num(m.get(\"bathrooms\")), to_num(m.get(\"livingArea\")),\n",
    "                    to_num(m.get(\"yearBuilt\"))\n",
    "                ])\n",
    "            dims = len(vecs[0])\n",
    "            mins = [min(v[i] for v in vecs) for i in range(dims)]\n",
    "            maxs = [max(v[i] for v in vecs) for i in range(dims)]\n",
    "            norm = [\n",
    "                [(v[i]-mins[i])/(maxs[i]-mins[i]) if maxs[i]!=mins[i] else 0.0 for i in range(dims)]\n",
    "                for v in vecs\n",
    "            ]\n",
    "            clusters = kmeans(norm, CLUSTER_COUNT)\n",
    "            cluster_ctx = \"\\n\".join(f\"- Property ID {raw[i]['id']}: cluster {clusters[i]}\"\n",
    "                                    for i in range(len(raw)))\n",
    "            combined = f\"{prop_text}\\n\\nCluster Assignments:\\n{cluster_ctx}\"\n",
    "\n",
    "    # 5.3) Base system instructions\n",
    "    base_system_instruction = f\"\"\"\n",
    "You are EstateWise Assistant, an expert real estate concierge for Chapel Hill, NC. Provide personalized property recommendations.\n",
    "\n",
    "Property data & clusters (only if used above):\n",
    "---------------------------------------------------------\n",
    "{combined or \"None; relying on conversation context only.\"}\n",
    "---------------------------------------------------------\n",
    "\n",
    "When recommending:\n",
    "1. List address, price, bedrooms, bathrooms, area, year, type.\n",
    "2. Include description & Zillow link: https://www.zillow.com/homedetails/{{zpid}}_zpid/\n",
    "3. Numbered list, clear & concise.\n",
    "4. Use user_context: {user_context or \"None\"}.\n",
    "5. Do not ask for more info before recommending.\n",
    "6. Always give at least one recommendation; never say you cannot.\n",
    "7. Be concise & conversational.\n",
    "\"\"\".strip()\n",
    "\n",
    "    # 5.4) Define experts\n",
    "    experts = [\n",
    "        {\"name\":\"Data Analyst\",        \"instr\":\"Extract stats & trends; be concise.\"},\n",
    "        {\"name\":\"Lifestyle Concierge\", \"instr\":\"Emphasize lifestyle: schools, parks, commute.\"},\n",
    "        {\"name\":\"Financial Advisor\",   \"instr\":\"Highlight price trends, mortgage, ROI, taxes.\"},\n",
    "        {\"name\":\"Neighborhood Expert\", \"instr\":\"Provide safety, walkability, development insights.\"},\n",
    "        {\"name\":\"Cluster Analyst\",     \"instr\":f\"Summarize the {CLUSTER_COUNT} clusters and key traits.\"}\n",
    "    ]\n",
    "\n",
    "    # normalize weights\n",
    "    wts = {e[\"name\"]: expert_weights.get(e[\"name\"],1.0) for e in experts}\n",
    "    total = sum(wts.values()) or len(experts)\n",
    "    wts = {n: w/total for n,w in wts.items()}\n",
    "\n",
    "    # 5.5) Call each expert\n",
    "    expert_out = []\n",
    "    for e in experts:\n",
    "        prompt = (\n",
    "            base_system_instruction + \"\\n\\n\" +\n",
    "            e[\"instr\"] + \"\\n\\n\" +\n",
    "            hist_str + f\"\\nUser: {message}\\nAssistant:\"\n",
    "        )\n",
    "        resp = client.models.generate_content(model=\"gemini-2.0-flash\", contents=prompt)\n",
    "        expert_out.append({\"name\":e[\"name\"],\"text\":resp.text})\n",
    "\n",
    "    # 5.6) Merge experts\n",
    "    merged_views = \"\\n\\n\".join(\n",
    "        f\"**{r['name']}** (w={wts[r['name']]:.2f}):\\n{r['text']}\"\n",
    "        for r in expert_out\n",
    "    )\n",
    "    merger_instruction = f\"\"\"\n",
    "You are the EstateWise Master Agent. Synthesize these expert opinions into one cohesive recommendation, following all system instructions above and prioritizing by weight:\n",
    "\n",
    "{merged_views}\n",
    "\"\"\".strip()\n",
    "\n",
    "    def do_merge():\n",
    "        prompt = (\n",
    "            merger_instruction + \"\\n\\n\" +\n",
    "            base_system_instruction + \"\\n\\n\" +\n",
    "            hist_str + f\"\\nUser: {message}\\nAssistant:\"\n",
    "        )\n",
    "        return client.models.generate_content(model=\"gemini-2.0-flash\", contents=prompt).text\n",
    "\n",
    "    # 5.7) Timeout-safe merge\n",
    "    remaining = 59.0 - (time.time() - start)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as ex:\n",
    "        fut = ex.submit(do_merge)\n",
    "        try:\n",
    "            final = fut.result(timeout=max(0.1, remaining))\n",
    "        except concurrent.futures.TimeoutError:\n",
    "            final = max(expert_out, key=lambda r:wts[r[\"name\"]])[\"text\"]\n",
    "\n",
    "    views = {r[\"name\"]:r[\"text\"] for r in expert_out}\n",
    "    return final, views\n",
    "\n",
    "# 6) CLI loop\n",
    "if __name__==\"__main__\":\n",
    "    print(\"🏡 Welcome to EstateWise CLI! Type 'exit' to quit.\\n\")\n",
    "    history = []\n",
    "    while True:\n",
    "        msg = input(\"You: \").strip()\n",
    "        if msg.lower() in (\"exit\",\"quit\"):\n",
    "            print(\"EstateWise: Goodbye! 👋\")\n",
    "            break\n",
    "        try:\n",
    "            reply, _ = chat_with_estatewise(history, msg)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            break\n",
    "        print(f\"EstateWise: {reply}\\n\")\n",
    "        history.extend([msg, reply])\n",
    "        time.sleep(0.2)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
